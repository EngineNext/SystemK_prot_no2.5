import os
import json
import glob
import re
from pypdf import PdfReader
import google.generativeai as genai
from dotenv import load_dotenv
import time

# --- 設定 ---
# .envファイルを読み込む
# ※実行ディレクトリにあれば自動で見つけますが、念のため明示的に読み込む
load_dotenv()

# APIキーの確認
if "GOOGLE_API_KEY" not in os.environ:
    print("[ERROR] GOOGLE_API_KEY not found. Please check your .env file.")
    exit(1)

genai.configure(api_key=os.environ["GOOGLE_API_KEY"])

# モデル設定 (高速なFlashモデル)
model = genai.GenerativeModel('gemini-1.5-flash')

# パス設定
PDF_DIR = os.path.join(os.path.dirname(__file__), 'pdfs')
OUTPUT_FILE = os.path.join(os.path.dirname(__file__), '../js/data.js')

def extract_relevant_text(pdf_path):
    print(f"[READ] Reading: {os.path.basename(pdf_path)}...")
    try:
        reader = PdfReader(pdf_path)
        relevant_text = ""
        hit_pages = 0
        keywords = ["配点", "共通テスト", "個別学力検査", "科目", "選抜方法"]
        
        for i, page in enumerate(reader.pages):
            text = page.extract_text()
            if not text: continue
            score = sum(1 for k in keywords if k in text)
            if score >= 2:
                print(f"  - Page {i+1} seems relevant (score: {score})")
                relevant_text += f"\n--- Page {i+1} ---\n{text}"
                hit_pages += 1
            if hit_pages >= 5: break
        
        if hit_pages == 0:
            print("  [WARN] No relevant pages found. Reading first 10 pages.")
            for i in range(min(10, len(reader.pages))):
                relevant_text += reader.pages[i].extract_text() + "\n"
        return relevant_text
    except Exception as e:
        print(f"[ERROR] PDF Error: {e}")
        return ""

def generate_university_data(text):
    if not text: return []
    print(f"[AI] Analyzing {len(text)} chars with Gemini...")
    time.sleep(2) 

    prompt = """
    以下のテキストは大学入試要項の抜粋です。
    ここから「学部・学科ごとの入試配点データ」を抽出し、指定のJSON形式のみを出力してください。
    
    【重要：配点の扱い】
    - 「共通テスト」と「個別試験（2次）」の配点比率が必要です。
    - 科目名（englishR, math1Aなど）は文脈から推測してマッピングしてください。
    - 英語のRとLの比率が不明な場合は 1:1 と仮定してください。
    
    【JSON出力例】
    [
        {
            "name": "大学名",
            "faculty": "学部名",
            "field": ["science"],
            "exams": [
                {
                    "type": "一般選抜前期",
                    "borderScoreRate": 0.75, 
                    "desc": "共通テスト重視",
                    "weights": {"englishR":1, "math1A":1}
                }
            ]
        }
    ]
    
    【対象テキスト】
    """ + text

    try:
        response = model.generate_content(prompt)
        json_str = response.text.strip()
        if "```json" in json_str:
            json_str = json_str.split("```json")[1].split("```")[0]
        elif "```" in json_str:
            json_str = json_str.split("```")[1].split("```")[0]
        return json.loads(json_str)
    except Exception as e:
        print(f"[ERROR] AI Error: {e}")
        return []

# --- 既存データの読み込み ---
def load_existing_data():
    if not os.path.exists(OUTPUT_FILE):
        return []
    
    try:
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            # 正規表現で const universities = [...]; の中身を取り出す
            match = re.search(r'const universities = (\[.*?\]);', content, re.DOTALL)
            if match:
                return json.loads(match.group(1))
    except Exception as e:
        print(f"[WARN] Could not load existing data: {e}")
    
    return []

# --- データ保存（マージ機能付き） ---
def save_to_js(new_data):
    # 1. 既存データをロード
    current_data = load_existing_data()
    print(f"[INFO] Loaded {len(current_data)} existing universities.")
    
    # 2. データをマージ
    data_map = {(u['name'], u['faculty']): u for u in current_data}
    
    added_count = 0
    updated_count = 0
    
    for uni in new_data:
        key = (uni['name'], uni['faculty'])
        if key in data_map:
            data_map[key] = uni # 更新
            updated_count += 1
        else:
            data_map[key] = uni # 追加
            added_count += 1
    
    merged_list = list(data_map.values())
    
    # 3. 書き込み
    header_content = """// --- Data Definitions ---
// Auto-generated by tools/generator.py

const conversionTables = {
    englishR:  { max: 100, points: [[100, 68.0], [80, 58.7], [60, 49.4], [40, 40.1], [20, 30.8], [0, 20.0]] },
    englishL:  { max: 100, points: [[100, 77.5], [80, 65.0], [60, 52.4], [40, 39.8], [20, 27.2], [0, 20.0]] },
    math1A:    { max: 100, points: [[100, 78.6], [80, 68.7], [60, 58.7], [40, 48.0], [20, 38.0], [0, 28.0]] },
    math2BC:   { max: 100, points: [[100, 68.5], [80, 59.4], [60, 50.3], [40, 41.1], [20, 32.0], [0, 22.0]] },
    japanese:  { max: 200, points: [[200, 79.9], [150, 63.2], [100, 46.6], [80, 39.9], [50, 29.9], [0, 20.0]] },
    jp_modern: { max: 110, points: [[110, 74.6], [90, 62.7], [70, 50.8], [50, 38.9], [30, 27.0], [10, 15.1]] },
    jp_ancient:{ max: 45, points: [[45, 72.0], [35, 62.3], [25, 52.6], [15, 42.9], [5, 30.0]] },
    jp_kanbun: { max: 45, points: [[45, 71.0], [35, 62.8], [25, 54.7], [15, 46.6], [5, 38.0]] },
    science:   { max: 100, points: [[100, 72.0], [80, 64.0], [60, 56.0], [40, 48.0], [20, 40.0], [0, 30.0]] },
    social:    { max: 100, points: [[100, 73.8], [80, 62.9], [60, 52.1], [40, 41.2], [20, 30.0], [0, 20.0]] },
    info:      { max: 100, points: [[100, 81.2], [80, 67.2], [60, 53.2], [40, 39.2], [20, 25.2], [0, 15.0]] }
};

const subjectMaster = {
    englishR: { name: '英語(R)', max: 100, table: 'englishR' },
    englishL: { name: '英語(L)', max: 100, table: 'englishL' },
    math1A:   { name: '数学I・A', max: 100, table: 'math1A' },
    math2BC:  { name: '数学II・B・C', max: 100, table: 'math2BC' },
    jp_modern: { name: '現代文', max: 110, table: 'jp_modern', isSub: true },
    jp_ancient:{ name: '古文', max: 45, table: 'jp_ancient', isSub: true },
    jp_kanbun: { name: '漢文', max: 45, table: 'jp_kanbun', isSub: true },
    info:     { name: '情報', max: 100, table: 'info' },
    science1: { name: '理科①', max: 100, table: 'science' },
    science2: { name: '理科②', max: 100, table: 'science' },
    social:   { name: '地歴公民', max: 100, table: 'social' },
    social1:  { name: '地歴公民①', max: 100, table: 'social' },
    social2:  { name: '地歴公民②', max: 100, table: 'social' },
    scienceBasic: { name: '理科基礎', max: 100, table: 'science' }
};
"""
    js_content = header_content + "\nconst universities = " + json.dumps(merged_list, indent=4, ensure_ascii=False) + ";"
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(js_content)
    print(f"[DONE] Data Saved! (New: {added_count}, Updated: {updated_count}, Total: {len(merged_list)})")

def main():
    all_universities = []
    pdf_files = glob.glob(os.path.join(PDF_DIR, "*.pdf"))
    
    if not pdf_files:
        print("[WARN] No PDF files found in tools/pdfs/")
        return

    for pdf_path in pdf_files:
        text = extract_relevant_text(pdf_path)
        if text:
            data = generate_university_data(text)
            all_universities.extend(data)
    
    if all_universities:
        save_to_js(all_universities)
    else:
        print("[WARN] No university data was generated.")

if __name__ == "__main__":
    main()if __name__ == "__main__":
    main()
