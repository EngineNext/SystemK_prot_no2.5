import os
import json
import glob
from pypdf import PdfReader
import google.generativeai as genai
from dotenv import load_dotenv

# --- è¨­å®š ---
# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€ã‹ã€ã“ã“ã«ç›´æ¥æ›¸ãï¼ˆéæ¨å¥¨ã ãŒãƒ†ã‚¹ãƒˆç”¨ãªã‚‰å¯ï¼‰
# os.environ["GOOGLE_API_KEY"] = "ã“ã“ã«Geminiã®APIã‚­ãƒ¼ã‚’å…¥ã‚Œã‚‹"
load_dotenv()

# Geminiã®è¨­å®š
genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-pro-latest')

# ãƒ•ã‚©ãƒ«ãƒ€è¨­å®š
PDF_DIR = os.path.join(os.path.dirname(__file__), 'pdfs')
OUTPUT_FILE = os.path.join(os.path.dirname(__file__), '../js/data.js')

def extract_text_from_pdf(pdf_path):
    print(f"ğŸ“„ Reading: {os.path.basename(pdf_path)}...")
    reader = PdfReader(pdf_path)
    text = ""
    # å…¨ãƒšãƒ¼ã‚¸èª­ã‚€ã¨é•·ã™ãã‚‹å ´åˆãŒã‚ã‚‹ã®ã§ã€å…¥è©¦ç§‘ç›®ãŒã‚ã‚Šãã†ãªãƒšãƒ¼ã‚¸ï¼ˆP10-50ãªã©ï¼‰ã«çµã‚‹ã®ã‚‚æ‰‹
    # ä»Šå›ã¯å…¨ãƒšãƒ¼ã‚¸èª­ã‚€
    for page in reader.pages:
        text += page.extract_text() + "\n"
    return text

def generate_university_data(text):
    print("ğŸ¤– Analyzing with Gemini...")
    
    prompt = """
    ã‚ãªãŸã¯å¤§å­¦å…¥è©¦ã®ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã®ã€Œå‹Ÿé›†è¦é …ã€ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æŒ‡å®šã•ã‚ŒãŸJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    
    ã€æŠ½å‡ºãƒ«ãƒ¼ãƒ«ã€‘
    1. å­¦éƒ¨ãƒ»å­¦ç§‘ã”ã¨ã€å…¥è©¦æ–¹å¼ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†ã‘ã‚‹ã“ã¨ã€‚
    2. ç§‘ç›®ã®é…ç‚¹ï¼ˆweightsï¼‰ã¯ã€å…±é€šãƒ†ã‚¹ãƒˆã®é…ç‚¹æ¯”ç‡ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã€‚
       - ç‰¹ã«è¨˜è¿°ãŒãªã‘ã‚Œã°æ¨™æº–ã‚’ã€Œ1ã€ã¨ã™ã‚‹ã€‚
       - è‹±èªã®ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°(R)ã¨ãƒªã‚¹ãƒ‹ãƒ³ã‚°(L)ã®æ¯”ç‡ã¯æ…é‡ã«åˆ¤å®šã™ã‚‹ã“ã¨ã€‚
    3. åˆæ ¼æœ€ä½ç‚¹ã‚„ãƒœãƒ¼ãƒ€ãƒ¼å¾—ç‚¹ç‡ï¼ˆborderScoreRateï¼‰ãŒãƒ†ã‚­ã‚¹ãƒˆã«ã‚ã‚Œã°æŠ½å‡ºã€‚ãªã‘ã‚Œã° 0.65 (65%) ã¨æ¨æ¸¬ã—ã¦å…¥ã‚Œã‚‹ã“ã¨ã€‚
    
    ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    ä»¥ä¸‹ã®JSONé…åˆ—å½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚Markdownã‚¿ã‚°ï¼ˆ```jsonï¼‰ã¯ä¸è¦ã§ã™ã€‚
    
    [
        {
            "name": "å¤§å­¦å",
            "faculty": "å­¦éƒ¨å",
            "field": ["science" | "humanities" ãªã©ã®åˆ†é‡ã‚¿ã‚°ã‚’2-3å€‹æ¨æ¸¬],
            "exams": [
                {
                    "type": "å…¥è©¦æ–¹å¼å (ä¾‹: å‰æœŸ, Aæ–¹å¼)",
                    "borderScoreRate": 0.75,
                    "desc": "æ–¹å¼ã®ç‰¹å¾´ã‚’20æ–‡å­—ç¨‹åº¦ã§è¦ç´„",
                    "weights": {
                        "englishR": 1, "englishL": 1, "math1A": 1, "math2BC": 1,
                        "science1": 1, "science2": 1, "social": 1, "info": 1,
                        "jp_modern": 1, "jp_ancient": 1, "jp_kanbun": 1
                    }
                }
            ]
        }
    ]
    
    ã€å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆã€‘
    """ + text[:30000] # æ–‡å­—æ•°åˆ¶é™å¯¾ç­–ï¼ˆé•·ã™ãã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚å†’é ­3ä¸‡æ–‡å­—ï¼‰

    try:
        response = model.generate_content(prompt)
        # JSONéƒ¨åˆ†ã ã‘ã‚’å–ã‚Šå‡ºã™ç°¡æ˜“çš„ãªå‡¦ç†
        json_str = response.text.strip()
        if "```json" in json_str:
            json_str = json_str.split("```json")[1].split("```")[0]
        elif "```" in json_str:
            json_str = json_str.split("```")[1].split("```")[0]
            
        return json.loads(json_str)
    except Exception as e:
        print(f"âŒ Error: {e}")
        return []

def save_to_js(universities_data):
    # æ—¢å­˜ã®é™çš„ãƒ‡ãƒ¼ã‚¿ï¼ˆJSå´ã®è¨­å®šãªã©ï¼‰ã¯æ®‹ã—ã¤ã¤ã€universitiesé…åˆ—ã ã‘æ›¸ãæ›ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ãŒ
    # ä»Šå›ã¯ data.js ã‚’ã€Œuniversitieså®šç¾©å°‚ç”¨ã€ã«ã—ãŸã®ã§ä¸¸ã”ã¨ä¸Šæ›¸ãã™ã‚‹
    
    # æ—¢å­˜ã®å›ºå®šãƒ‡ãƒ¼ã‚¿ã‚’å®šç¾©ï¼ˆæ¶ˆã—ãŸããªã„å®šæ•°ãªã©ï¼‰
    header_content = """// --- Data Definitions ---
// Auto-generated by tools/generator.py

const conversionTables = {
    englishR:  { max: 100, points: [[100, 68.0], [80, 58.7], [60, 49.4], [40, 40.1], [20, 30.8], [0, 20.0]] },
    englishL:  { max: 100, points: [[100, 77.5], [80, 65.0], [60, 52.4], [40, 39.8], [20, 27.2], [0, 20.0]] },
    math1A:    { max: 100, points: [[100, 78.6], [80, 68.7], [60, 58.7], [40, 48.0], [20, 38.0], [0, 28.0]] },
    math2BC:   { max: 100, points: [[100, 68.5], [80, 59.4], [60, 50.3], [40, 41.1], [20, 32.0], [0, 22.0]] },
    japanese:  { max: 200, points: [[200, 79.9], [150, 63.2], [100, 46.6], [80, 39.9], [50, 29.9], [0, 20.0]] },
    jp_modern: { max: 110, points: [[110, 74.6], [90, 62.7], [70, 50.8], [50, 38.9], [30, 27.0], [10, 15.1]] },
    jp_ancient:{ max: 45, points: [[45, 72.0], [35, 62.3], [25, 52.6], [15, 42.9], [5, 30.0]] },
    jp_kanbun: { max: 45, points: [[45, 71.0], [35, 62.8], [25, 54.7], [15, 46.6], [5, 38.0]] },
    science:   { max: 100, points: [[100, 72.0], [80, 64.0], [60, 56.0], [40, 48.0], [20, 40.0], [0, 30.0]] },
    social:    { max: 100, points: [[100, 73.8], [80, 62.9], [60, 52.1], [40, 41.2], [20, 30.0], [0, 20.0]] },
    info:      { max: 100, points: [[100, 81.2], [80, 67.2], [60, 53.2], [40, 39.2], [20, 25.2], [0, 15.0]] }
};

const subjectMaster = {
    englishR: { name: 'è‹±èª(R)', max: 100, table: 'englishR' },
    englishL: { name: 'è‹±èª(L)', max: 100, table: 'englishL' },
    math1A:   { name: 'æ•°å­¦Iãƒ»A', max: 100, table: 'math1A' },
    math2BC:  { name: 'æ•°å­¦IIãƒ»Bãƒ»C', max: 100, table: 'math2BC' },
    jp_modern: { name: 'ç¾ä»£æ–‡', max: 110, table: 'jp_modern', isSub: true },
    jp_ancient:{ name: 'å¤æ–‡', max: 45, table: 'jp_ancient', isSub: true },
    jp_kanbun: { name: 'æ¼¢æ–‡', max: 45, table: 'jp_kanbun', isSub: true },
    info:     { name: 'æƒ…å ±', max: 100, table: 'info' },
    science1: { name: 'ç†ç§‘â‘ ', max: 100, table: 'science' },
    science2: { name: 'ç†ç§‘â‘¡', max: 100, table: 'science' },
    social:   { name: 'åœ°æ­´å…¬æ°‘', max: 100, table: 'social' },
    social1:  { name: 'åœ°æ­´å…¬æ°‘â‘ ', max: 100, table: 'social' },
    social2:  { name: 'åœ°æ­´å…¬æ°‘â‘¡', max: 100, table: 'social' },
    scienceBasic: { name: 'ç†ç§‘åŸºç¤', max: 100, table: 'science' }
};
"""

    # è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜
    js_content = header_content + "\nconst universities = " + json.dumps(universities_data, indent=4, ensure_ascii=False) + ";"
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(js_content)
    print(f"âœ… Updated {OUTPUT_FILE} with {len(universities_data)} universities!")

def main():
    all_universities = []
    
    # pdfsãƒ•ã‚©ãƒ«ãƒ€å†…ã®PDFã‚’å…¨èµ°æŸ»
    pdf_files = glob.glob(os.path.join(PDF_DIR, "*.pdf"))
    
    if not pdf_files:
        print("âš ï¸ No PDF files found in tools/pdfs/")
        return

    for pdf_path in pdf_files:
        text = extract_text_from_pdf(pdf_path)
        if text:
            data = generate_university_data(text)
            all_universities.extend(data)
    
    # JSãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    save_to_js(all_universities)

if __name__ == "__main__":
    main()
